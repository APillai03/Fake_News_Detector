{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6348f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1f1c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c4dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f648327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_characters  num_words  num_sentences  avg_sentence_length  num_capitalized_words  num_exclamations  num_questions  has_clickbait_words  readability_score  sentiment_polarity  sentiment_subjectivity  class  PROPN       ADV   VERB       DET     CCONJ   PRON    ADP   PART   NOUN    ADJ       NUM     SCONJ       AUX\n",
      "0        0.055838   0.055107       0.076720             0.119048               0.006329          0.045113       0.095745                  0.0           0.936917            0.541066                0.599895      0  0.200  0.180180  0.120  0.201201  0.197605  0.222  0.073  0.155  0.158  0.078  0.023952  0.081081  0.125333\n",
      "1        0.036627   0.037962       0.037037             0.164048               0.009494          0.000000       0.000000                  0.0           0.929556            0.497498                0.334098      0  0.197  0.096096  0.097  0.282282  0.155689  0.096  0.129  0.080  0.184  0.090  0.059880  0.130631  0.128000\n",
      "2        0.069430   0.065271       0.079365             0.136429               0.104430          0.015038       0.042553                  1.0           0.937315            0.493828                0.541969      0  0.152  0.090090  0.152  0.180180  0.101796  0.258  0.099  0.195  0.186  0.058  0.011976  0.117117  0.130667\n",
      "3        0.053540   0.050331       0.058201             0.141825               0.015823          0.000000       0.010638                  0.0           0.932948            0.488441                0.394086      0  0.131  0.183183  0.127  0.300300  0.161677  0.142  0.095  0.180  0.202  0.044  0.000000  0.108108  0.213333\n",
      "4        0.045276   0.051678       0.050265             0.167460               0.000000          0.000000       0.000000                  0.0           0.935140            0.494139                0.495222      0  0.109  0.072072  0.156  0.276276  0.239521  0.200  0.137  0.295  0.164  0.045  0.029940  0.094595  0.120000\n"
     ]
    }
   ],
   "source": [
    "print(df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1699e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"class\", axis=1) \n",
    "y = df[\"class\"]                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b96a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fd4e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eb0ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Fake_News_Detector\\env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(24,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),                      \n",
    "    Dense(1, activation='sigmoid')                     \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ba60c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m6,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,177</span> (196.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,177\u001b[0m (196.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,177</span> (196.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,177\u001b[0m (196.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fe63c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04c55972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0327 - val_accuracy: 0.9109 - val_loss: 0.4670\n",
      "Epoch 2/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0386 - val_accuracy: 0.9109 - val_loss: 0.4616\n",
      "Epoch 3/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0355 - val_accuracy: 0.9110 - val_loss: 0.4525\n",
      "Epoch 4/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0343 - val_accuracy: 0.9180 - val_loss: 0.4675\n",
      "Epoch 5/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0275 - val_accuracy: 0.9159 - val_loss: 0.5127\n",
      "Epoch 6/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0291 - val_accuracy: 0.9117 - val_loss: 0.5066\n",
      "Epoch 7/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0295 - val_accuracy: 0.9133 - val_loss: 0.4664\n",
      "Epoch 8/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0232 - val_accuracy: 0.9066 - val_loss: 0.5116\n",
      "Epoch 9/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0261 - val_accuracy: 0.9102 - val_loss: 0.4729\n",
      "Epoch 10/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0329 - val_accuracy: 0.9134 - val_loss: 0.5000\n",
      "Epoch 11/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0174 - val_accuracy: 0.9186 - val_loss: 0.5401\n",
      "Epoch 12/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0275 - val_accuracy: 0.9128 - val_loss: 0.4974\n",
      "Epoch 13/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0198 - val_accuracy: 0.9088 - val_loss: 0.5378\n",
      "Epoch 14/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0233 - val_accuracy: 0.9105 - val_loss: 0.5049\n",
      "Epoch 15/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0199 - val_accuracy: 0.9102 - val_loss: 0.5277\n",
      "Epoch 16/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0218 - val_accuracy: 0.9106 - val_loss: 0.5211\n",
      "Epoch 17/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0220 - val_accuracy: 0.9146 - val_loss: 0.5650\n",
      "Epoch 18/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0200 - val_accuracy: 0.9121 - val_loss: 0.5434\n",
      "Epoch 19/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0208 - val_accuracy: 0.9151 - val_loss: 0.5142\n",
      "Epoch 20/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0231 - val_accuracy: 0.9179 - val_loss: 0.5661\n",
      "Epoch 21/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0175 - val_accuracy: 0.9150 - val_loss: 0.5611\n",
      "Epoch 22/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0214 - val_accuracy: 0.9196 - val_loss: 0.5569\n",
      "Epoch 23/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0168 - val_accuracy: 0.9137 - val_loss: 0.6004\n",
      "Epoch 24/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0197 - val_accuracy: 0.9157 - val_loss: 0.5633\n",
      "Epoch 25/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.9119 - val_loss: 0.5311\n",
      "Epoch 26/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0239 - val_accuracy: 0.9072 - val_loss: 0.6229\n",
      "Epoch 27/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 0.0172 - val_accuracy: 0.9146 - val_loss: 0.5753\n",
      "Epoch 28/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.9099 - val_loss: 0.5436\n",
      "Epoch 29/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0173 - val_accuracy: 0.9140 - val_loss: 0.6026\n",
      "Epoch 30/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0196 - val_accuracy: 0.9155 - val_loss: 0.6095\n",
      "Epoch 31/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0165 - val_accuracy: 0.9144 - val_loss: 0.6352\n",
      "Epoch 32/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0202 - val_accuracy: 0.9150 - val_loss: 0.6293\n",
      "Epoch 33/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0177 - val_accuracy: 0.9133 - val_loss: 0.5909\n",
      "Epoch 34/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0151 - val_accuracy: 0.9107 - val_loss: 0.5958\n",
      "Epoch 35/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0216 - val_accuracy: 0.9198 - val_loss: 0.5897\n",
      "Epoch 36/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0124 - val_accuracy: 0.9110 - val_loss: 0.7445\n",
      "Epoch 37/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0173 - val_accuracy: 0.9182 - val_loss: 0.5841\n",
      "Epoch 38/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0179 - val_accuracy: 0.9144 - val_loss: 0.5914\n",
      "Epoch 39/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0142 - val_accuracy: 0.9146 - val_loss: 0.7260\n",
      "Epoch 40/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0164 - val_accuracy: 0.9178 - val_loss: 0.6273\n",
      "Epoch 41/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0148 - val_accuracy: 0.9118 - val_loss: 0.6759\n",
      "Epoch 42/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0181 - val_accuracy: 0.9150 - val_loss: 0.6652\n",
      "Epoch 43/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0123 - val_accuracy: 0.9128 - val_loss: 0.6547\n",
      "Epoch 44/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.9094 - val_loss: 0.6240\n",
      "Epoch 45/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0201 - val_accuracy: 0.9135 - val_loss: 0.6465\n",
      "Epoch 46/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0144 - val_accuracy: 0.9069 - val_loss: 0.6980\n",
      "Epoch 47/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0174 - val_accuracy: 0.9178 - val_loss: 0.6716\n",
      "Epoch 48/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0097 - val_accuracy: 0.9094 - val_loss: 0.6868\n",
      "Epoch 49/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0165 - val_accuracy: 0.9163 - val_loss: 0.6477\n",
      "Epoch 50/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0123 - val_accuracy: 0.9161 - val_loss: 0.7030\n",
      "Epoch 51/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0142 - val_accuracy: 0.9165 - val_loss: 0.6142\n",
      "Epoch 52/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0118 - val_accuracy: 0.9112 - val_loss: 0.7291\n",
      "Epoch 53/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0197 - val_accuracy: 0.9214 - val_loss: 0.7332\n",
      "Epoch 54/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0094 - val_accuracy: 0.9138 - val_loss: 0.6625\n",
      "Epoch 55/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0103 - val_accuracy: 0.9122 - val_loss: 0.7107\n",
      "Epoch 56/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0245 - val_accuracy: 0.9175 - val_loss: 0.6419\n",
      "Epoch 57/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0102 - val_accuracy: 0.9157 - val_loss: 0.6208\n",
      "Epoch 58/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0119 - val_accuracy: 0.9127 - val_loss: 0.5934\n",
      "Epoch 59/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0128 - val_accuracy: 0.9108 - val_loss: 0.6865\n",
      "Epoch 60/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0084 - val_accuracy: 0.9150 - val_loss: 0.7350\n",
      "Epoch 61/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0162 - val_accuracy: 0.9183 - val_loss: 0.5995\n",
      "Epoch 62/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0145 - val_accuracy: 0.9174 - val_loss: 0.6667\n",
      "Epoch 63/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0119 - val_accuracy: 0.9121 - val_loss: 0.6710\n",
      "Epoch 64/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0123 - val_accuracy: 0.9143 - val_loss: 0.6683\n",
      "Epoch 65/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0137 - val_accuracy: 0.9121 - val_loss: 0.7049\n",
      "Epoch 66/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0138 - val_accuracy: 0.9101 - val_loss: 0.7028\n",
      "Epoch 67/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0084 - val_accuracy: 0.9104 - val_loss: 0.6190\n",
      "Epoch 68/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0120 - val_accuracy: 0.9150 - val_loss: 0.6428\n",
      "Epoch 69/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.9213 - val_loss: 0.6689\n",
      "Epoch 70/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0189 - val_accuracy: 0.9135 - val_loss: 0.6785\n",
      "Epoch 71/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0138 - val_accuracy: 0.9180 - val_loss: 0.7413\n",
      "Epoch 72/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.9141 - val_loss: 0.7200\n",
      "Epoch 73/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0107 - val_accuracy: 0.9171 - val_loss: 0.7910\n",
      "Epoch 74/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0141 - val_accuracy: 0.9136 - val_loss: 0.7029\n",
      "Epoch 75/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 0.9158 - val_loss: 0.6619\n",
      "Epoch 76/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.9094 - val_loss: 0.5884\n",
      "Epoch 77/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.9161 - val_loss: 0.7418\n",
      "Epoch 78/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0057 - val_accuracy: 0.9128 - val_loss: 0.7617\n",
      "Epoch 79/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0105 - val_accuracy: 0.9060 - val_loss: 0.6905\n",
      "Epoch 80/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0136 - val_accuracy: 0.9137 - val_loss: 0.6108\n",
      "Epoch 81/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0092 - val_accuracy: 0.9150 - val_loss: 0.7169\n",
      "Epoch 82/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.9166 - val_loss: 0.7605\n",
      "Epoch 83/1000\n",
      "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.9133 - val_loss: 0.7539\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',      \n",
    "    patience=30,               \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7077474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.6635\n",
      "Test Accuracy: 0.9214\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
